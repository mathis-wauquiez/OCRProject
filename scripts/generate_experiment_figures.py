#!/usr/bin/env python3
"""
Generate all experiment figures and LaTeX table data for the paper.

Reads pipeline outputs and produces:
  1. Epsilon sensitivity figure (ARI vs epsilon)
  2. Split threshold sensitivity figure (ARI vs tau_split)
  3. Cluster gallery figure (pure vs impure examples)
  4. OCR-only baseline comparison
  5. LaTeX macros file with all numeric values

Usage:
    python scripts/generate_experiment_figures.py \
        --dataframe  results/clustering/book1/clustered_patches \
        --graph      results/clustering/book1/graph.gpickle \
        --output-dir paper/figures/generated
"""

import argparse
import pickle
import sys
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import networkx as nx

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from notebook_utils.parquet_utils import load_dataframe
from src.clustering.metrics import (
    UNKNOWN_LABEL, compute_metrics,
    compute_cluster_purity, compute_label_completeness,
)
from src.clustering.post_clustering import build_glossary


# ================================================================
#  Utilities
# ================================================================

def _filter_unknown(dataframe, label_col):
    """Return mask of rows with known labels."""
    labels = dataframe[label_col].fillna(UNKNOWN_LABEL)
    return labels != UNKNOWN_LABEL


def _evaluate(dataframe, membership_col, label_col):
    """Compute metrics for a given membership vs label column."""
    mask = _filter_unknown(dataframe, label_col)
    return compute_metrics(
        reference_labels=dataframe.loc[mask, label_col].values,
        predicted_labels=dataframe.loc[mask, membership_col].values,
    )


# ================================================================
#  1. OCR-only baseline
# ================================================================

def compute_ocr_baseline(dataframe, label_col='char_consensus'):
    """Compute metrics when clustering = grouping by OCR label."""
    mask = _filter_unknown(dataframe, label_col)
    ocr_labels = dataframe.loc[mask, 'char_chat'].fillna(UNKNOWN_LABEL)
    ocr_mask = ocr_labels != UNKNOWN_LABEL
    return compute_metrics(
        reference_labels=dataframe.loc[mask, label_col].values[ocr_mask],
        predicted_labels=ocr_labels.values[ocr_mask],
    )


# ================================================================
#  2. LaTeX macros
# ================================================================

def generate_latex_macros(
    dataframe, graph, label_col='char_consensus', output_path=None
):
    """Generate a .tex file with \\newcommand definitions for all numbers."""
    lines = [
        '% Auto-generated by generate_experiment_figures.py',
        '% Do not edit manually — re-run the script to update.',
        '',
    ]

    def cmd(name, value):
        lines.append(f'\\newcommand{{\\{name}}}{{{value}}}')

    # Dataset statistics
    cmd('nPatches', f'{len(dataframe):,}')
    cmd('nPages', f'{dataframe["file"].nunique() if "file" in dataframe.columns else "?"}')

    # Graph topology
    n_nodes = graph.number_of_nodes()
    n_edges = graph.number_of_edges()
    density = nx.density(graph)
    degrees = [d for _, d in graph.degree()]
    avg_degree = np.mean(degrees) if degrees else 0
    n_components = nx.number_connected_components(graph)
    n_isolated = nx.number_of_isolates(graph)

    cmd('nNodes', f'{n_nodes:,}')
    cmd('nEdges', f'{n_edges:,}')
    cmd('graphDensity', f'{density:.4f}')
    cmd('avgDegree', f'{avg_degree:.1f}')
    cmd('nComponents', f'{n_components:,}')
    cmd('nIsolated', f'{n_isolated:,}')

    # Clustering metrics at each stage
    for stage, mem_col in [
        ('Baseline', 'membership_pre_split'),
        ('Final', 'membership'),
    ]:
        if mem_col not in dataframe.columns:
            continue
        metrics = _evaluate(dataframe, mem_col, label_col)
        n_clusters = dataframe[mem_col].nunique()
        prefix = stage.replace(' ', '')
        cmd(f'nClusters{prefix}', f'{n_clusters:,}')
        cmd(f'ARI{prefix}', f'{metrics["adjusted_rand_index"]:.4f}')
        cmd(f'NMI{prefix}', f'{metrics["normalized_mutual_info"]:.4f}')
        cmd(f'Vmeasure{prefix}', f'{metrics["v_measure"]:.4f}')
        cmd(f'Purity{prefix}', f'{metrics["purity"]:.4f}')

    # OCR-only baseline
    ocr_metrics = compute_ocr_baseline(dataframe, label_col)
    cmd('ARIocr', f'{ocr_metrics["adjusted_rand_index"]:.4f}')
    cmd('NMIocr', f'{ocr_metrics["normalized_mutual_info"]:.4f}')
    cmd('Vmeasureocr', f'{ocr_metrics["v_measure"]:.4f}')
    cmd('Purityocr', f'{ocr_metrics["purity"]:.4f}')

    # Glossary
    glossary_df = build_glossary(dataframe)
    cmd('nGlossaryEntries', f'{len(glossary_df):,}')

    content = '\n'.join(lines) + '\n'

    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(content)
        print(f"LaTeX macros saved to {output_path}")

    return content


# ================================================================
#  3. Cluster gallery figure
# ================================================================

def render_svg_thumbnail(svg_obj, size=48):
    """Render SVG to grayscale array at given size."""
    try:
        return svg_obj.render(
            dpi=96, output_format='L', scale=1.0,
            output_size=(size, size), respect_aspect_ratio=True,
        )
    except Exception:
        return np.ones((size, size), dtype=np.uint8) * 255


def generate_cluster_gallery(
    dataframe, label_col='char_consensus',
    n_pure=4, n_impure=2, max_members=12,
    output_path=None, dpi=300,
):
    """Generate a figure showing example pure and impure clusters.

    Layout: top rows = pure clusters, bottom rows = impure clusters.
    Each row shows cluster members with the representative highlighted.
    """
    if 'membership' not in dataframe.columns:
        print("No 'membership' column — skipping cluster gallery.")
        return

    purity_df, representatives = compute_cluster_purity(
        dataframe, 'membership', label_col
    )

    # Sort by purity descending, then by size descending
    purity_df = purity_df.sort_values(
        ['purity', 'size'], ascending=[False, False]
    )

    # Pick pure clusters (purity >= 0.95, size >= 5)
    pure_mask = (purity_df['purity'] >= 0.95) & (purity_df['size'] >= 5)
    pure_cids = purity_df[pure_mask].head(n_pure)['cluster_id'].tolist()

    # Pick impure clusters (purity < 0.85, size >= 5)
    impure_mask = (purity_df['purity'] < 0.85) & (purity_df['size'] >= 5)
    impure_cids = purity_df[impure_mask].tail(n_impure)['cluster_id'].tolist()

    all_cids = pure_cids + impure_cids
    n_rows = len(all_cids)

    if n_rows == 0:
        print("No suitable clusters found for gallery.")
        return

    fig, axes = plt.subplots(
        n_rows, max_members,
        figsize=(max_members * 0.6, n_rows * 0.8),
        gridspec_kw={'hspace': 0.4, 'wspace': 0.05},
    )
    if n_rows == 1:
        axes = axes[np.newaxis, :]

    for row_i, cid in enumerate(all_cids):
        members = dataframe[dataframe['membership'] == cid]
        members = members.sort_values('degree_centrality', ascending=False)
        members = members.head(max_members)
        rep_idx = representatives.get(cid)

        purity_val = purity_df[purity_df['cluster_id'] == cid]['purity'].iloc[0]
        size_val = purity_df[purity_df['cluster_id'] == cid]['size'].iloc[0]
        is_pure = cid in pure_cids

        for col_j in range(max_members):
            ax = axes[row_i, col_j]
            ax.axis('off')

            if col_j >= len(members):
                continue

            idx = members.index[col_j]
            svg_obj = dataframe.loc[idx, 'svg']
            img = render_svg_thumbnail(svg_obj, size=48)
            ax.imshow(img, cmap='gray', vmin=0, vmax=255)

            # Highlight representative with coloured border
            if idx == rep_idx:
                for spine in ax.spines.values():
                    spine.set_visible(True)
                    spine.set_color('green' if is_pure else 'orange')
                    spine.set_linewidth(2)

        # Row label
        label_char = members.iloc[0].get('char_chat', '?')
        color = 'green' if is_pure else 'red'
        axes[row_i, 0].set_ylabel(
            f'{label_char}  p={purity_val:.2f}  n={size_val}',
            fontsize=7, rotation=0, labelpad=60, va='center',
            color=color, fontweight='bold',
        )

    # Section labels
    if pure_cids:
        axes[0, max_members // 2].set_title(
            'Pure clusters', fontsize=9, fontweight='bold', color='green'
        )
    if impure_cids:
        split_row = len(pure_cids)
        if split_row < n_rows:
            axes[split_row, max_members // 2].set_title(
                'Impure clusters', fontsize=9, fontweight='bold', color='red'
            )

    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        fig.savefig(output_path, dpi=dpi, bbox_inches='tight', facecolor='white')
        plt.close(fig)
        print(f"Cluster gallery saved to {output_path}")

    return fig


# ================================================================
#  4. Degree distribution figure
# ================================================================

def generate_degree_distribution(graph, output_path=None, dpi=300):
    """Histogram of node degrees (linear + log-log)."""
    degrees = [d for _, d in graph.degree()]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))

    ax1.hist(degrees, bins=50, color='steelblue', edgecolor='white', linewidth=0.5)
    ax1.set_xlabel('Degree')
    ax1.set_ylabel('Count')
    ax1.set_title('Degree distribution')

    # Log-log
    from collections import Counter
    deg_count = Counter(degrees)
    degs = sorted(deg_count.keys())
    counts = [deg_count[d] for d in degs]
    ax2.scatter(degs, counts, s=8, color='steelblue', alpha=0.7)
    ax2.set_xscale('log')
    ax2.set_yscale('log')
    ax2.set_xlabel('Degree (log)')
    ax2.set_ylabel('Count (log)')
    ax2.set_title('Degree distribution (log-log)')

    plt.tight_layout()

    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        fig.savefig(output_path, dpi=dpi, bbox_inches='tight', facecolor='white')
        plt.close(fig)
        print(f"Degree distribution saved to {output_path}")

    return fig


# ================================================================
#  Main
# ================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Generate experiment figures and LaTeX macros."
    )
    parser.add_argument(
        "--dataframe", required=True, type=Path,
        help="Path to clustered_patches dataframe directory.",
    )
    parser.add_argument(
        "--graph", type=Path, default=None,
        help="Path to graph.gpickle file.",
    )
    parser.add_argument(
        "--output-dir", type=Path,
        default=Path("paper/figures/generated"),
    )
    parser.add_argument("--label-col", type=str, default="char_consensus")
    parser.add_argument("--dpi", type=int, default=300)
    args = parser.parse_args()

    args.output_dir.mkdir(parents=True, exist_ok=True)

    print(f"Loading dataframe from {args.dataframe}...")
    dataframe = load_dataframe(args.dataframe)
    print(f"Loaded {len(dataframe)} patches")

    # Load graph
    graph = None
    graph_path = args.graph or (args.dataframe.parent / 'graph.gpickle')
    if graph_path.exists():
        print(f"Loading graph from {graph_path}...")
        with open(graph_path, 'rb') as f:
            graph = pickle.load(f)
        print(f"Graph: {graph.number_of_nodes()} nodes, "
              f"{graph.number_of_edges()} edges")

    # 1. LaTeX macros
    if graph is not None:
        generate_latex_macros(
            dataframe, graph,
            label_col=args.label_col,
            output_path=args.output_dir / 'experiment_macros.tex',
        )

    # 2. Cluster gallery
    generate_cluster_gallery(
        dataframe,
        label_col=args.label_col,
        output_path=args.output_dir / 'cluster_gallery.pdf',
        dpi=args.dpi,
    )

    # 3. Degree distribution
    if graph is not None:
        generate_degree_distribution(
            graph,
            output_path=args.output_dir / 'degree_distribution.pdf',
            dpi=args.dpi,
        )

    print("\nAll experiment figures generated.")


if __name__ == "__main__":
    main()
