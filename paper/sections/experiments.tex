% ============================================================================
%  Experiments — Results and Evaluation
% ============================================================================

\section{Experiments}
\label{sec:experiments}


% ============================================================================
\subsection{Dataset}
\label{sec:dataset}

We evaluate on the \emph{Ying huan zhi lue} (Brief Records of the World, 1848), a Chinese book printed from individually carved woodblocks.
The corpus contains \nPages{} page images from which the extraction pipeline produces approximately \nPatches{} character patches.
Each character was uniquely engraved---no two occurrences share the same printing block---making this a maximally challenging scenario for visual clustering.

Ground-truth labels are obtained at two levels:
\begin{itemize}[nosep]
    \item \textbf{OCR predictions} ($\ell_\text{chat}$): Kraken model output, used during hyperparameter selection to avoid methodological leak.
    \item \textbf{Consensus labels} ($\ell_\text{consensus}$): agreement between OCR predictions and aligned transcription labels, used only for final evaluation.
\end{itemize}


% ============================================================================
\subsection{Evaluation Metrics}
\label{sec:eval-protocol}

Clustering quality is measured using the metrics summarised in Table~\ref{tab:metrics}.
Characters with unknown ground-truth labels are excluded from all metric computations.

\begin{table}[t]
    \centering
    \small
    \caption{Evaluation metrics and their interpretation.}
    \label{tab:metrics}
    \begin{tabular}{@{}lp{7.5cm}@{}}
        \toprule
        \textbf{Metric} & \textbf{Description} \\
        \midrule
        ARI~\cite{hubert1985comparing} & Chance-adjusted pairwise agreement; primary metric. \\
        NMI & Information-theoretic overlap; robust to different cluster counts. \\
        V-measure~\cite{rosenberg2007v} & Harmonic mean of homogeneity and completeness. \\
        Purity & Fraction of majority-label members per cluster (weighted by cluster size). \\
        \bottomrule
    \end{tabular}
\end{table}

\paragraph{Hyperparameter selection.}
The pipeline performs a grid sweep over epsilon thresholds ($\varepsilon \in \{1.5{\times}10^{-4}, 2{\times}10^{-4}, 2.5{\times}10^{-4}, 3.8{\times}10^{-4}, 10^{-3}\}$) and Leiden resolution ($\gamma \in \{1.0, 1.25, 1.5, 1.75, 2.0\}$) using the CPM partition type.
The configuration maximising ARI on OCR-derived labels is selected; final metrics are reported on consensus labels.


% ============================================================================
\subsection{Results}
\label{sec:results}

\begin{table}[t]
    \centering
    \small
    \caption{Clustering results on the \emph{Ying huan zhi lue} corpus.
    Metrics are computed on consensus labels after each refinement stage.
    $K$ denotes the number of clusters.}
    \label{tab:main-results}
    \begin{tabular}{@{}lccccc@{}}
        \toprule
        \textbf{Stage} & \textbf{$K$} & \textbf{ARI} & \textbf{NMI} & \textbf{V-measure} & \textbf{Purity} \\
        \midrule
        Leiden (baseline)    & \nClustersBaseline  & \ARIBaseline  & \NMIBaseline  & \VmeasureBaseline  & \PurityBaseline  \\
        + Refinement (final) & \nClustersFinal     & \ARIFinal     & \NMIFinal     & \VmeasureFinal     & \PurityFinal     \\
        \midrule
        OCR-only baseline    & ---                  & \ARIocr       & \NMIocr       & \Vmeasureocr       & \Purityocr       \\
        \bottomrule
    \end{tabular}
\end{table}

Table~\ref{tab:main-results} reports clustering quality at each stage of the pipeline.
The Leiden partition provides the initial grouping; the two-stage refinement (Hausdorff splitting followed by label splitting) improves both purity and overall ARI.
The OCR-only baseline (clustering by predicted label) provides an informative comparison: it uses no visual similarity and relies entirely on the linguistic signal.

\paragraph{Graph topology.}
The NFA similarity graph contains \nNodes{} nodes and \nEdges{} edges (density~\graphDensity), with an average degree of~\avgDegree.
Isolated characters ($d{=}0$) are predominantly rare or damaged glyphs, while high-degree nodes correspond to frequent characters with many visually similar instances.


% ============================================================================
\subsection{Hyperparameter Sensitivity}
\label{sec:sensitivity}

% ── Epsilon sweep ──
\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{figures/generated/epsilon_sensitivity.pdf}
    \caption{Sensitivity to the NFA threshold $\varepsilon$.
    ARI is plotted as a function of $\varepsilon$ for each partition type.
    Error bars indicate standard deviation over the resolution sweep.}
    \label{fig:epsilon-sweep}
\end{figure}

\paragraph{NFA threshold.}
The epsilon parameter controls graph sparsity: smaller $\varepsilon$ yields stricter matching (fewer edges, more clusters), while larger $\varepsilon$ produces denser graphs.
Figure~\ref{fig:epsilon-sweep} shows ARI as a function of $\varepsilon$.
% TODO: Describe the optimal region and robustness.

% ── Split threshold sweep ──
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/generated/split_threshold.pdf}
    \caption{Sensitivity to the Hausdorff split threshold $\tau_\text{split}$.
    \emph{Left:} clustering metrics vs.\ $\tau_\text{split}$; the best ARI is marked by a dashed line.
    \emph{Right:} total number of clusters and number of clusters actually split.}
    \label{fig:split-threshold}
\end{figure}

\paragraph{Split threshold.}
The Hausdorff dendrogram cut $\tau_\text{split}$ trades off cluster purity against fragmentation.
Figure~\ref{fig:split-threshold} shows that ARI peaks at an intermediate value of $\tau_\text{split}$: too low splits every cluster into singletons, while too high leaves impure clusters intact.
% TODO: Report the optimal value and comment on robustness.


% ============================================================================
\subsection{Ablation Studies}
\label{sec:ablations}

% ── A1: HOG configuration ──
\paragraph{HOG configuration (A1).}
We compare HOG descriptor configurations varying cell size, gradient smoothing $\sigma$, and number of orientation bins.
% Uncomment once generated:
% \input{figures/generated/ablation_a1_hog_config}

% ── A2: Partition type ──
\paragraph{Partition type (A2).}
We compare the CPM objective against modularity (RBConfiguration) under the Leiden algorithm.
% Uncomment once generated:
% \input{figures/generated/ablation_a2_partition_type}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/generated/ablation_a2_partition_type.pdf}
    \caption{CPM vs.\ modularity (RBConfiguration): ARI as a function of the resolution parameter $\gamma$.
    CPM consistently achieves higher ARI across the resolution range.}
    \label{fig:ablation-partition}
\end{figure}

% ── A4: Reciprocal edges ──
\paragraph{Reciprocal edges (A4).}
We evaluate the effect of the reciprocal condition (Eq.~\ref{eq:reciprocal}) on graph construction.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/generated/ablation_a4_reciprocal.pdf}
    \caption{Reciprocal vs.\ non-reciprocal edge construction: ARI as a function of $\varepsilon$.
    The reciprocal condition improves clustering by removing asymmetric, unreliable edges.}
    \label{fig:ablation-reciprocal}
\end{figure}


% ============================================================================
\subsection{Qualitative Results}
\label{sec:qualitative}

% ── Cluster gallery ──
\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figures/generated/cluster_gallery.pdf}
    \caption{Example clusters from the final partition.
    Each row shows members of one cluster, with the representative (highest degree centrality) highlighted with a green border.
    \emph{Top rows:} pure clusters with consistent character identity.
    \emph{Bottom rows:} impure clusters where visually similar but distinct characters were grouped together.}
    \label{fig:cluster-gallery}
\end{figure*}

Figure~\ref{fig:cluster-gallery} shows example clusters.
Pure clusters demonstrate that the pipeline reliably groups visually identical characters.
Impure clusters reveal failure modes: typically characters with very similar stroke structures that differ in a single stroke.

% ── Glossary ──
\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figures/generated/glossary.pdf}
    \caption{Character glossary produced by the pipeline, showing the \nGlossaryEntries{} most frequent characters sorted by occurrence count.
    Each cell displays the vectorised representative of one cluster along with the OCR-predicted label and count.}
    \label{fig:glossary}
\end{figure*}

The final glossary (Fig.~\ref{fig:glossary}) provides a comprehensive inventory of all distinct character forms found in the book.
% TODO: Comment on the quality, discuss Zipfian frequency distribution.

% ── Reverse manuscript ──
\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/generated/reverse_manuscript/reverse_with_bg_page_000.png}
        \caption{Vectorised characters overlaid on the original scan (faded).}
        \label{fig:reverse-with-bg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/generated/reverse_manuscript/reverse_no_bg_page_000.png}
        \caption{Vectorised characters on a clean background.}
        \label{fig:reverse-no-bg}
    \end{subfigure}
    \caption{Reverse typography output for a representative page.
    \textbf{(a)}~Vectorised character outlines (blue) are overlaid on the faded original scan, demonstrating alignment quality.
    \textbf{(b)}~The same vectorised characters rendered on a white background, illustrating the clean reconstruction achievable by the pipeline.}
    \label{fig:reverse-manuscript}
\end{figure*}

Figure~\ref{fig:reverse-manuscript} demonstrates the end-to-end reverse typography result: vectorised character outlines placed at their original positions reconstruct the full page layout.
The overlay view~(a) confirms that the extracted and vectorised characters align well with the original print, while the clean-background view~(b) showcases the vectorisation quality.
