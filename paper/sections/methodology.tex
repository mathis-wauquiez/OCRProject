% ============================================================================
%  Methodology Section — Historical Document Character Clustering Pipeline
% ============================================================================

\section{Methodology}
\label{sec:methodology}

Our goal is to produce, from a collection of scanned historical document pages, a vectorised, clean glossary of the distinct character forms they contain—together with the ability to reprint any page from that glossary alone.
The approach rests on a simple observation: each character type appears many times throughout a printed book, yet the defects affecting each occurrence—ink spread, paper damage, uneven woodblock wear—are essentially random and independent.
The cleanest copy of a character, the one closest to the intended form, is therefore the one that best matches all the others: since it is unlikely that every printed instance would share the same artefact, defects can only reduce similarity, never increase it.

Exploiting this requires four steps:
\begin{enumerate*}[label=(\roman*)]
\item extracting individual characters from each page and attaching provisional OCR labels (\S\ref{sec:extraction}),
\item converting the resulting raster patches into clean, vectorised glyphs (\S\ref{sec:preprocessing}),
\item grouping characters into clusters within a principled statistical framework that naturally surfaces the cleanest representative of each type (\S\ref{sec:acontrario}), and
\item refining these clusters and assembling the final glossary (\S\ref{sec:refinement}).
\end{enumerate*}
Figure~\ref{fig:pipeline-overview} gives an overview.

\input{figures/methodology/fig_pipeline_overview}


% ============================================================================
\subsection{Character Extraction and Recognition}
\label{sec:extraction}

Before characters can be compared, they must be located on the page, segmented into individual patches, and tentatively labelled.

% ── (a) CRAFT-based character detection ──
\paragraph{Character detection.}
We detect character regions with CRAFT~\cite{baek2019character} (\textit{Character Region Awareness for Text Detection}), a fully convolutional network built on a VGG-16 encoder with a U-Net-style decoder.
CRAFT produces two per-pixel score maps at half the input resolution: a \emph{region score} $S_r(x,y) \in [0,1]$, encoding the probability that pixel $(x,y)$ lies at the centre of a character, and an \emph{affinity score} $S_a(x,y)$, encoding the probability that it lies between two adjacent characters.
The region score forms a Gaussian-like blob around each character centre; the affinity score links neighbouring characters into words.
Since Chinese text consists of discrete, spatially separated characters with no inter-character ligatures, we use only the region score and discard the affinity map entirely.

CRAFT is trained in a weakly supervised fashion: first on synthetic data with character-level annotations, then fine-tuned on real images using pseudo character-level ground truth generated by the model itself and weighted by a confidence score reflecting how well the predicted character count matches the known word length.
This strategy allows pre-trained weights to generalise to unseen scripts.
We use these pre-trained weights without fine-tuning, at magnification ratio~$5.0$ (canvas size 1280\,px) to ensure that even small characters on densely printed pages are adequately resolved.

From the region score map, individual character regions are extracted via dual-threshold watershed: pixels with $S_r \ge \tau_\text{text} = 0.6$ serve as seeds, and basins expand until $S_r$ drops below $\tau_\text{mask} = 0.3$.
This differs from CRAFT's default post-processing, which applies a single threshold followed by connected component labelling; the watershed approach better handles composite characters whose sub-components produce moderate but distinct peaks.
Components whose area falls below 10\,px are discarded as noise.

% ── (b) Binarisation and component association ──
\paragraph{Binarisation and component association.}
CRAFT's region score is a soft heatmap; what we need are crisp binary masks faithful to the original ink.
The page is therefore binarised in parallel with Otsu's method, yielding sharp connected components.
These components are then matched to CRAFT detections: each one is assigned to the CRAFT region whose elliptic distance, measured via negative Mahalanobis distance from the region's inertia tensor, is smallest.
The Mahalanobis distance accounts for the elongated shape of some character regions (e.g.\ horizontal or vertical strokes) that a simple Euclidean distance would misjudge.
This produces character candidates that carry both a binary image and a precise bounding box.
Candidates whose bounding box falls outside the expected range ($30 \times 30$ to $250 \times 250$\,px) or whose filled area is too small ($<700$\,px$^2$) are filtered out.

% ── M1.1: Extraction segmentation figure ──
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{\figExtractionSeg}
    \caption{Character extraction result on a representative page.
    Bounding boxes show the final character candidates after CRAFT detection,
    watershed segmentation, Mahalanobis association, and post-filtering.
    Colour coding indicates deletion reasons for discarded components.}
    \label{fig:extraction-segmentation}
\end{figure}

% ── M1.3: CRAFT deletion reasons figure ──
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{\figCraftDeletion}
    \caption{CRAFT detection with deletion-reason overlay.
    Components that pass all filters are shown in green; discarded
    components are colour-coded by rejection criterion (red~=~area too
    small, orange~=~aspect ratio too low, purple~=~high aspect ratio,
    pink~=~box too small, magenta~=~box too large, blue~=~too close to
    page contour).}
    \label{fig:craft-deletion}
\end{figure}

% ── (c) Layout analysis ──
\paragraph{Layout analysis and reading order.}
With characters detected, we need a reading order.
A projection-based layout module identifies columns and sub-columns from vertical ink-density profiles computed on the binarised image.
Within each column, rows are segmented using vertical projections; further subdivision into sub-columns handles cases where multiple text lanes coexist.
Characters are then numbered following the right-to-left, top-to-bottom convention of classical Chinese.
Figure~\ref{fig:layout-analysis} illustrates the result on a representative page.

% ── M1.4: Layout analysis figure ──
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{\figLayoutAnalysis}
    \caption{Layout analysis result showing column and sub-column detection.
    \emph{Top:} horizontal ink-density projection with detected column
    boundaries.
    \emph{Bottom:} page image with column overlays (distinct colours) and
    sub-column boundaries (dashed lines within each column).
    The reading order proceeds right-to-left across columns and
    top-to-bottom within each sub-column.}
    \label{fig:layout-analysis}
\end{figure}

% ── (d) Character recognition ──
\paragraph{Character recognition.}
Each character is labelled by a Kraken-based~\cite{kiessling2019kraken} model trained on similar historical Chinese documents, operating at the sub-column level.
Within each sub-column, a baseline is estimated from the median of the character $x$-barycenters, and the predicted character sequence is spatially matched to CRAFT detections via the Hungarian algorithm on vertical distances.
Unmatched positions receive an unknown token~$\square$, so that every character carries a label $\ell_i \in \mathcal{A} \cup \{\square\}$.
These labels are provisional—they serve primarily during the refinement stage (\S\ref{sec:refinement}), not during matching itself.

When an external transcription is available, it is aligned to the OCR output via Levenshtein edit distance, yielding a ground-truth label for each patch (Section~\ref{sec:eval-protocol}).


% ============================================================================
\subsection{Preprocessing}
\label{sec:preprocessing}

The raster patches produced by extraction are not yet comparable: they differ in skew, noise level, and resolution.
Comparing them at the pixel level would conflate true shape differences with irrelevant imaging artefacts.
What we need is a representation that captures the geometric form of each character—its strokes, their relative positions and orientations—while discarding noise and resolution dependence.
We achieve this by correcting rotation, cleaning the binary mask, and converting the result into a smooth vector outline.
Figure~\ref{fig:preprocessing} illustrates the three steps on representative examples.

% ── M2.1: Preprocessing before/after figure ──
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{\figPreprocessing}
    \caption{Preprocessing pipeline for individual character patches.
    \emph{Top row:} raw image patches extracted by CRAFT.
    \emph{Middle row:} binarised patches after Otsu thresholding and morphological cleaning.
    \emph{Bottom row:} vectorised SVG outlines produced by affine scale-space smoothing.}
    \label{fig:preprocessing}
\end{figure}

% ── (a) Rotation correction ──
\paragraph{Rotation correction.}
Scanned pages are rarely perfectly aligned, and the skew angle may vary from one scan to the next.
We estimate it with LSD~\cite{von2010lsd} (\textit{Line Segment Detector}), aggregating dominant line-segment orientations via a length-weighted circular mean:
\begin{equation}
    \theta = \tfrac{1}{2}\arg\!\left(\textstyle\sum_i w_i \, e^{2\mathrm{i}\alpha_i}\right),
    \label{eq:skew}
\end{equation}
where $w_i$ and $\alpha_i$ are the length and orientation of each detected segment.
The estimated angle $\theta$ is applied as a global rotation to every patch on the page.

% ── (b) Ink filter ──
\paragraph{Ink filter.}
The corrected binary patches are cleaned by area opening and area closing, removing foreground specks below 5\,px and background holes below 10\,px.
This produces crisp binary images ready for vectorisation.

% ── (c) Vectorisation via affine scale-space ──
\paragraph{Vectorisation via affine scale-space.}
We vectorise the cleaned patches using affine scale-space smoothing~\cite{alvarez1993axioms,ciomaga2017curvature}, a geometric PDE that evolves each level line according to its curvature:
\begin{equation}
    \frac{\partial u}{\partial t} = |\nabla u|\, \kappa^{1/3},
    \label{eq:gass}
\end{equation}
where $\kappa$ denotes the curvature of the level line through each point.
The $1/3$ exponent makes the evolution affine-invariant: the smoothed shape does not depend on the viewing angle.
This is particularly relevant for woodblock-printed documents, where printing pressure, paper curvature, and ink spread introduce local affine distortions that differ from one copy to the next.
Ordinary Gaussian smoothing would reduce noise but also blur sharp stroke endings; affine scale-space smoothing removes small-scale irregularities while preserving the large-scale calligraphic structure.
The resulting smooth contours are converted to SVG outlines, giving each character a resolution-independent, calligraphy-faithful representation.


% ============================================================================
\subsection{A Contrario Matching and Clustering}
\label{sec:acontrario}

With all characters now represented as comparable vector outlines, the central question is: which of them depict the same glyph?
We answer it by describing each character with a shape descriptor, scoring pairwise similarity within a statistical framework, and partitioning the resulting graph.

% ── (a) HOG descriptors ──
\paragraph{HOG descriptors.}
We describe each character outline with a Histogram of Oriented Gradients (HOG) descriptor~\cite{dalal2005histograms}.
HOG is a natural choice for Chinese characters, whose identity is largely determined by the number, orientation, and spatial arrangement of their strokes: two characters that differ by a single stroke will produce measurably different orientation histograms, while two copies of the same character will agree on the dominant orientations despite local noise.

The SVG is rasterised at a fixed resolution into a grid of $C \times C$ cells.
Gradients are computed with Gaussian derivative filters (smoothing parameter~$\sigma$) and accumulated into $B$ unsigned orientation bins per cell via trilinear interpolation:
\begin{equation}
    h_b = \sum_{(x,y) \in \text{cell}} m(x,y) \cdot \bigl[(1 - \alpha)\,\delta_{b, \lfloor \hat\theta \rfloor} + \alpha\,\delta_{b, (\lfloor \hat\theta \rfloor + 1) \bmod B}\bigr],
\end{equation}
where $\hat\theta = \theta \cdot B$ and $\alpha = \hat\theta - \lfloor\hat\theta\rfloor$.
The full descriptor is normalised with L2-clip-L2 (clipping threshold~$t$); specific values are reported in Section~\ref{sec:experiments}.

\input{figures/methodology/fig_hog_descriptor}

% ── M3.1: HOG descriptor example figure ──
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{\figHogDescriptor}
    \caption{HOG descriptor computation on a representative character.
    From left to right: rendered SVG, gradient magnitude, gradient orientation, and the resulting HOG descriptor (orientation bins $\times$ cell index).}
    \label{fig:hog-example}
\end{figure}

% ── (b) Dissimilarity metric ──
\paragraph{Dissimilarity metric.}
We compare pairs of HOG descriptors $\mathbf{h}^A, \mathbf{h}^B$ (each with $K$ cells of $B$ bins) using the Circular Earth Mover's Distance (CEMD) per cell.
Because orientation bins are arranged on a circle, a naive bin-to-bin distance such as L2 would treat adjacent bins as independent and penalise small angular shifts disproportionately.
CEMD instead measures the minimum amount of ``work'' needed to transform one histogram into the other along the circular axis.
With cumulative difference $X_j = \sum_{i=1}^{j} h^A_{k,i} - \sum_{i=1}^{j} h^B_{k,i}$, the per-cell cost is:
\begin{equation}
    \text{CEMD}(h^A_k, h^B_k) = \min_{s \in \{0,\ldots,B{-}2\}} \frac{1}{B}\sum_{j=1}^{B} |X_j - X_s|.
    \label{eq:cemd}
\end{equation}
The total dissimilarity between two characters is $D(\mathbf{h}^A, \mathbf{h}^B) = \sum_{k=1}^{K} \text{CEMD}(h^A_k, h^B_k)$.

% ── (c) Number of False Alarms ──
\paragraph{Number of False Alarms.}
Raw dissimilarities are not directly comparable across characters: a rare, intricate glyph with many strokes will have a higher baseline distance to anything else than a simple, frequent one.
A fixed threshold would therefore be too strict for complex characters and too lax for simple ones.
The \textit{a contrario} framework~\cite{desolneux2000meaningful} resolves this by normalising each dissimilarity relative to the distribution observed for that specific character.

Under the null model (random pairing), $D$ is approximately Gaussian with character-specific moments $(\mu_A, \sigma_A^2)$ estimated from all pairwise comparisons involving character~$A$.
The Number of False Alarms is:
\begin{equation}
    \text{NFA}(A,B) = N^2 \cdot \Phi\!\left(\frac{D(\mathbf{h}^A, \mathbf{h}^B) - \mu_A}{\sigma_A}\right),
    \label{eq:nfa}
\end{equation}
where $\Phi$ is the standard normal CDF and $N$ the number of tokens.
Two characters are deemed \emph{meaningfully} similar when $\text{NFA} \le \varepsilon$.
In practice we store the negative log-NFA: $\text{NLFA}(A,B) = -\log\Phi\!\bigl(\frac{D - \mu_A}{\sigma_A}\bigr)$.

This framework does more than decide which characters match—it also realises the observation from the introduction.
Recall that printing defects are random and independent across occurrences.
The cleanest copy of a character, the one closest to the ideal form, will pass the NFA test against many partners, because its shape is close to the shared template that all copies approximate.
A defective copy, by contrast, will fail the test against most partners, because its distortions push it away from that template.
As a result, the cleanest copy naturally acquires the highest degree in the similarity graph.
We exploit this directly when selecting glossary representatives (\S\ref{sec:refinement}).

% ── M3.2: A contrario distribution figure ──
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{\figAContrario}
    \caption{A contrario null-hypothesis test.
    \emph{Left:} histogram of pairwise dissimilarities for a query character and the fitted Gaussian null model $\mathcal{N}(\mu_A, \sigma_A^2)$.
    Characters with dissimilarity in the far left tail are \emph{meaningful} matches.
    \emph{Right:} per-character null-model parameters $(\mu_i, \sigma_i)$ across the corpus; the query character is marked in red.}
    \label{fig:a-contrario}
\end{figure}

% ── (d) Graph construction ──
\paragraph{Similarity graph.}
The NFA scores define a similarity graph $G = (V, E, w)$ with one vertex per character token.
An edge $(i,j)$ is created when both directions pass the significance threshold $\tau_\text{NFA} = -\log\varepsilon + 2\log N$:
\begin{equation}
    (i,j) \in E \iff \text{NLFA}(i,j) \ge \tau_\text{NFA} \;\wedge\; \text{NLFA}(j,i) \ge \tau_\text{NFA}.
    \label{eq:reciprocal}
\end{equation}
Requiring both directions matters because the NFA is inherently directional: each character has its own null distribution.
Character~$A$ may find~$B$ surprisingly close relative to $A$'s distribution, while $B$ does not find~$A$ surprising relative to its own.
The reciprocal condition filters out such one-sided matches, keeping only mutually confirmed similarities.
Edge weights are the symmetrised NLFA: $w_{ij} = \tfrac{1}{2}[\text{NLFA}(i,j) + \text{NLFA}(j,i)]$.

% ── (e) Correlation clustering ──
\paragraph{Clustering formulation.}
The task is now to partition the $N$ tokens into clusters, one per distinct character form.
Several properties of the problem constrain the choice of method: the NFA scores are ordinal—they rank pairs by similarity but are not calibrated probabilities; the number of distinct characters is unknown \textit{a priori} (though a lower bound is available from the OCR vocabulary); and the cluster-size distribution is expected to follow a Zipf law, with a few high-frequency characters and many rare ones.

We cast this as a \emph{correlation clustering} problem~\cite{bansal2004correlation}: given a graph whose edges encode pairwise similarity, find the partition that minimises the total \emph{disagreement}—the cost of co-clustering dissimilar tokens plus the cost of separating similar ones.

\paragraph{CPM objective.}
For a resolution parameter $\gamma \in (0,1)$, the \emph{LambdaCC} disagreement objective~\cite{veldt2018correlation} is:
\begin{equation}
    \mathcal{L}_\gamma(\mathcal{C}) = \!\sum_{(i,j)\in E}\!(1{-}\gamma)\, x_{ij}
        + \!\sum_{(i,j)\notin E}\!\gamma\,(1{-}x_{ij}),
    \label{eq:lambdacc}
\end{equation}
where $x_{ij} = 0$ if $i,j$ are co-clustered and $1$ otherwise.
Expanding in terms of within-cluster edge count $e_c$ and cluster size $n_c$ reveals that $\mathcal{L}_\gamma = \text{const} - \mathcal{Q}_\gamma$, with
\begin{equation}
    \mathcal{Q}_\gamma = \sum_{c} \left[e_c - \gamma \binom{n_c}{2}\right]
    \label{eq:cpm}
\end{equation}
the Constant Potts Model (CPM) quality function~\cite{traag2011narrow}.
Minimising disagreement is therefore equivalent to maximising $\mathcal{Q}_\gamma$.

The CPM corresponds to a Reichardt--Bornholdt model~\cite{reichardt2006statistical} with an Erd\H{o}s--R\'enyi null model ($P_{ij} = \text{const}$), as opposed to the configuration-model null model that yields modularity.
We prefer CPM for three reasons:
\begin{enumerate}[nosep]
    \item \emph{No resolution limit.}  Modularity cannot resolve clusters smaller than ${\sim}\sqrt{2m}$ edges~\cite{fortunato2007resolution}, which would merge rare characters.  CPM has no such limitation.
    \item \emph{Ordinal compatibility.}  Only the relative ordering of edge weights matters, not their absolute calibration—appropriate for NFA-derived scores.
    \item \emph{Density interpretation.}  The parameter $\gamma$ has a direct meaning: every cluster in an optimal partition has internal edge density $\ge \gamma$.
\end{enumerate}

\paragraph{Optimisation.}
We maximise $\mathcal{Q}_\gamma$ with the Leiden algorithm~\cite{traag2019louvain}, which guarantees well-connected communities and runs in seconds at our scale (${\sim}$\nNodes{} tokens, ${\sim}$\nEdges{} edges).
Both $\varepsilon$ and $\gamma$ are swept jointly, and the configuration maximising ARI with respect to OCR labels is retained (Section~\ref{sec:sensitivity}).

\input{figures/methodology/fig_clustering_pipeline}


% ============================================================================
\subsection{Cluster Refinement, Glossary Construction, and Reverse Printing}
\label{sec:refinement}

Community detection optimises a global objective and offers no per-cluster purity guarantee; in practice, the Leiden partition may contain mixed or over-fragmented clusters.
A two-stage refinement corrects these errors before the glossary is assembled (Fig.~\ref{fig:refinement-pipeline}).

% ── (a) Hausdorff-based splitting ──
\paragraph{Stage~1: Hausdorff-based splitting.}
The HOG-based NFA graph captures overall shape similarity at the level of stroke orientations, but it may not distinguish characters that share the same gross structure yet differ in fine details.
To catch such cases, we re-examine clusters with five or more members using pairwise Hausdorff distances~\cite{rony2025hausdorff} computed on registered binary images.
Registration relies on multiscale inverse compositional alignment~\cite{briand2018ipol}, which compensates for residual positional and scale differences between patches.
An average-linkage dendrogram is built from the Hausdorff distance matrix and cut at threshold~$\tau_\text{split}$, selected via an ARI-based sweep on OCR-derived labels (Section~\ref{sec:sensitivity}).

% ── (b) Label-based splitting ──
\paragraph{Stage~2: Label-based splitting.}
Within each cluster, members sharing the same OCR label are grouped together.
Groups of two or more form their own sub-clusters; smaller groups are dissolved into singletons.
Members with unknown labels are assigned to the dominant sub-cluster.

After both stages, every refined cluster is pure with respect to OCR labels and more compact in Hausdorff distance than its Leiden ancestor.

\input{figures/methodology/fig_refinement_pipeline}

% ── Glossary construction ──
\paragraph{Glossary construction.}
The refined clusters are consolidated into a \emph{character glossary}.
For each OCR-predicted character, we identify the cluster containing the most occurrences and select its most central member—by degree centrality in the NFA similarity graph—as the representative.
As argued in Section~\ref{sec:acontrario}, the most central member is also the one most likely to be free of printing defects: it is the copy that best matches all others, and therefore the closest approximation to the intended glyph.
Ties between equally sized clusters are broken by mean intra-cluster dissimilarity, favouring the more cohesive group.
The glossary records the dominant label, cluster size, and representative index for every distinct character form, sorted by frequency.

% ── Reverse printing ──
\paragraph{Reverse printing.}
Given the glossary, any page can be reconstructed as a vector document.
For each character detection on a page, we look up the glossary representative of its cluster and render its SVG outline at the corresponding bounding-box position and scale.
Because the representative was selected as the cleanest copy, the reconstructed page is not merely a reproduction of the original—it is a \emph{restored} version, in which printing defects have been replaced by the best available exemplar of each character.
