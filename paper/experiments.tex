% ============================================================================
%  Experiments â€” Ablation Studies, Comparisons, and Evaluation Protocol
% ============================================================================

\section{Experiments}
\label{sec:experiments}

This section describes the evaluation protocol, ablation studies, and comparative experiments.


% ============================================================================
\subsection{Evaluation Protocol}
\label{sec:eval-protocol}

\paragraph{Metrics.}
All metrics are computed against manually annotated reference labels (not OCR-derived).
Table~\ref{tab:metrics} summarises the evaluation metrics.

\begin{table}[t]
    \centering
    \small
    \caption{Evaluation metrics and their interpretation.}
    \label{tab:metrics}
    \begin{tabular}{@{}lp{7.5cm}@{}}
        \toprule
        \textbf{Metric} & \textbf{Description} \\
        \midrule
        ARI~\cite{hubert1985comparing} & Chance-adjusted pairwise agreement; primary metric. \\
        NMI & Information-theoretic overlap; robust to different cluster counts. \\
        V-measure~\cite{rosenberg2007v} & Harmonic mean of homogeneity and completeness. \\
        Per-class F1 & Precision/recall per character class via Hungarian matching. \\
        Noise fraction & Fraction classified as noise (HDBSCAN only). \\
        \bottomrule
    \end{tabular}
\end{table}

\paragraph{Ground truth.}
At least 500 characters from each corpus are manually annotated by two independent annotators; inter-annotator agreement is reported via Cohen's~$\kappa$.

\paragraph{Statistical significance.}
For main comparisons: mean and standard deviation over 5 bootstrap sub-samplings, paired Wilcoxon signed-rank test, and Cohen's $d$ effect size.


% ============================================================================
\subsection{Ablation Studies}
\label{sec:ablations}

Each ablation isolates one variable while holding others at their default setting.
We report ARI, NMI, V-measure, and the number of clusters.

\subsubsection{Feature Representation (A1--A4)}

\begin{table}[t]
    \centering
    \small
    \caption{Feature representation ablations.}
    \label{tab:ablation-features}
    \begin{tabular}{@{}llp{5.5cm}@{}}
        \toprule
        \textbf{ID} & \textbf{Variable} & \textbf{Variants} \\
        \midrule
        A1 & HOG cell size & $8{\times}8$, $12{\times}12$, $16{\times}16$, $24{\times}24$\,px \\
        A2 & Orientation bins & 4, 8, 12, 16, 24 unsigned bins \\
        A3 & Feature type & HOG, Shape Context, Learned (CNN), HOG + persistent homology \\
        A4 & Dissimilarity & CEMD vs.\ Sinkhorn OT \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{A Contrario Framework (A5--A7)}

\begin{table}[t]
    \centering
    \small
    \caption{A contrario framework ablations.}
    \label{tab:ablation-acontrario}
    \begin{tabular}{@{}llp{5.5cm}@{}}
        \toprule
        \textbf{ID} & \textbf{Variable} & \textbf{Variants} \\
        \midrule
        A5 & Background model & Independent cells, Empirical (bootstrap), Gamma-fitted \\
        A6 & Gaussianity & Q-Q plots at $K = 4, 16, 36, 64$ cells \\
        A7 & NFA threshold & $\varepsilon \in \{0.01, 0.1, 1, 10, 100\}$ \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Clustering and Refinement (A8--A13)}

\begin{table}[t]
    \centering
    \small
    \caption{Clustering and refinement ablations.}
    \label{tab:ablation-clustering}
    \begin{tabular}{@{}llp{5.5cm}@{}}
        \toprule
        \textbf{ID} & \textbf{Variable} & \textbf{Variants} \\
        \midrule
        A8 & Clustering algorithm & Connected comp., HDBSCAN, AP, Louvain, Leiden \\
        A9 & HDBSCAN min\_cluster\_size & $\{2, 3, 5, 10, 20\}$ \\
        A10 & HDBSCAN min\_samples & $\{1, 3, 5, 10, 15\}$ \\
        A11 & Refinement method & None, 2-stage, K-medoids, MRF, HDBSCAN \\
        A12 & MRF weight $\beta$ & $\{0.1, 0.5, 1, 2, 5\} / \text{med.\ NLFA}$ \\
        A13 & Stage ablation & Full, $-$S1, $-$S2, none \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Registration (A14--A15)}

\begin{table}[t]
    \centering
    \small
    \caption{Registration ablations.}
    \label{tab:ablation-registration}
    \begin{tabular}{@{}llp{5.5cm}@{}}
        \toprule
        \textbf{ID} & \textbf{Variable} & \textbf{Variants} \\
        \midrule
        A14 & Registration method & None, Pairwise affine, MST, Congealing \\
        A15 & Impact on clustering & Full pipeline $\pm$ registration \\
        \bottomrule
    \end{tabular}
\end{table}


% ============================================================================
\subsection{Comparative Experiments}
\label{sec:comparisons}

\subsubsection{Baselines}

\begin{table}[t]
    \centering
    \small
    \caption{Baseline methods for comparison.}
    \label{tab:baselines}
    \begin{tabular}{@{}lp{8cm}@{}}
        \toprule
        \textbf{Baseline} & \textbf{Description} \\
        \midrule
        B1: K-means on HOG & HOG + $k$-means ($K$ = ground-truth classes). Tests the \textit{a contrario} contribution. \\
        B2: Learned + K-means & Contrastive ResNet-18 embeddings + $k$-means. Tests feature representation. \\
        B3: OCR-only & Cluster by OCR-predicted label. Upper bound on linguistic signal. \\
        B4: End-to-end & Fine-tuned segmentation + classification (if available). \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Cross-Corpus Generalisation}

The pipeline is run with identical hyperparameters on $\ge 3$ corpora: (i)~medieval Latin manuscripts, (ii)~early modern printed text, (iii)~non-Latin script (e.g., Hebrew or Arabic).
We report the performance drop relative to per-corpus tuning, testing whether the \textit{a contrario} framework adapts to data distribution.

\subsubsection{Scalability}

The pipeline is run on subsets of increasing size ($n \in \{500, 1\text{k}, 2\text{k}, 5\text{k}, 10\text{k}, 15\text{k}\}$) to verify complexity bounds: NFA computation $O(N^2)$, Leiden community detection, Hausdorff splitting $O(m^2)$ per cluster, and PCA rematching.
